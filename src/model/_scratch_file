#!/usr/bin/env python3
import random

import lightning
import torch
from torch.utils.data import Subset, DataLoader

from src.dataset.SymDataModule import custom_collate_fn, SymDataModule
from src.dataset.transforms.ComposeTransform import ComposeTransform
from src.dataset.transforms.RandomSampler import RandomSampler
from src.dataset.transforms.UnitSphereNormalization import UnitSphereNormalization
from src.metrics.eval_script import calculate_metrics_from_predictions, get_match_sequence_plane_symmetry
from src.model.LightingCenterNNormalsNet import LightingCenterNNormalsNet

if __name__ == "__main__":
    DATA_PATH = "/data/sym-10k-xz-split-class-noparallel/"  # "/data/temp"#
    MODEL_PATH = "/home/gustavo_santelices/Documents/Universidad/2024-1/simetrias/models/aa/epoch=9_plane_train_map_epoch=0.156_plane_train_loss_epoch=0.34068.ckpt"
    BATCH_SIZE = 2
    PREDICT_SAMPLES = 4
    SAMPLE_SIZE = 14_440
    COLLATE_FN = custom_collate_fn
    NUM_WORKERS = 0

    scaler = UnitSphereNormalization()
    sampler = RandomSampler(sample_size=SAMPLE_SIZE, keep_copy=True)
    compose_transform = ComposeTransform([sampler, scaler])
    #compose_transform = ComposeTransform([scaler])

    SHAPE_TYPE = {
        "astroid": 0,
        "citrus": 1,
        "cylinder": 2,
        "egg_keplero": 3,
        "geometric_petal": 4,
        "lemniscate": 5,
        "m_convexities": 6,
        "mouth_curve": 7,
        "revolution": 8,
        "square": 9,
    }

    datamodule = SymDataModule(
        dataset_path=DATA_PATH,
        predict_data_path=DATA_PATH,
        does_predict_has_ground_truths=True,
        batch_size=BATCH_SIZE,
        transform=compose_transform,
        collate_function=custom_collate_fn,
        shuffle=True,
        n_workers=1,
    )
    datamodule.setup("predict")
    datamodule.setup("fit")

    print(len(datamodule.train_dataset))

    test_net = LightingCenterNNormalsNet.load_from_checkpoint(MODEL_PATH)

    test_batch = next(iter(datamodule.train_dataloader()))

    trainer = lightning.Trainer(enable_progress_bar=True, logger=False)  # , fast_dev_run=True
    #trainer.fit(test_net, datamodule)

    print(f'Training dataset has: {len(datamodule.train_dataset) = } batches')
    train_dataloader = datamodule.train_dataloader()
    print(f'Train dataloader has: {len(train_dataloader) = } batches')
    val_dataloader = datamodule.val_dataloader()
    print(f'Valid dataloader has: {len(val_dataloader) = } batches')

    predict_dataset = Subset(datamodule.train_dataset, [i for i in range(PREDICT_SAMPLES)])
    print(f'Predict dataset has: {len(predict_dataset) = } batches')
    predict_dataloader = DataLoader(predict_dataset, batch_size=BATCH_SIZE,
                                    collate_fn=COLLATE_FN, num_workers=NUM_WORKERS)
    print(f'Predict dataloader has: {len(predict_dataloader) = } batches')

    predictions = trainer.predict(test_net, predict_dataloader)

    print(f'Predictions: {len(predictions)}')
    pr_idx = random.randint(0, len(predictions) - 1)
    print(f'Taking batch no. {pr_idx}')
    batch, plane_predictions, _, _ = predictions[pr_idx]

    eval_predictions = [(batch.get_points(), plane_predictions, batch.get_plane_syms())]

    torch.set_printoptions(linewidth=200)
    torch.set_printoptions(precision=3)
    torch.set_printoptions(sci_mode=False)

    print(f"Batch size: {batch.size}")
    idx = random.randint(0, batch.size - 1)
    item = batch.item_list[idx]
    print(f"Comparing element: {idx} in batch...")
    gt = item.plane_symmetries

    c_hat, match_pred, match_true, _, _ = test_net.matcher.get_optimal_assignment(batch.get_points(), plane_predictions,
                                                                                  batch.get_plane_syms())
    bundled_predictions = (batch, plane_predictions, c_hat, match_pred, match_true)
    loss, others = test_net.plane_loss(bundled_predictions)

    pr = plane_predictions[idx][plane_predictions[idx][:, -1].sort(descending=True).indices]
    pr = pr[pr[:, -1] > 0.1]



    matches = get_match_sequence_plane_symmetry(item.points, plane_predictions[idx], item.plane_symmetries, {
        "eps": 0.01,
        "theta": 0.00015230484,
        "confidence_threshold": 0.0,
    })

    print(f'Ground truth:\n{gt}')
    print(f'Prediction  :\n{pr}')

    map_, phc, _ = calculate_metrics_from_predictions(eval_predictions, get_match_sequence_plane_symmetry, {
        "eps": 0.01,
        "theta": 0.00015230484,
        "confidence_threshold": 0.0,
    })

    print("Normal metrics")
    print("PHC", map_.item())
    print("MAP", phc.item())
    print(f'Matches  :\n{matches}')


    map_, phc, _ = calculate_metrics_from_predictions(eval_predictions, get_match_sequence_plane_symmetry, {
        "eps": 0.01,
        "theta": 0.00137046524,
        "confidence_threshold": 0.0,
    })

    matches = get_match_sequence_plane_symmetry(item.points, plane_predictions[idx], item.plane_symmetries, {
        "eps": 0.01,
        "theta": 0.00137046524,
        "confidence_threshold": 0.0,
    })

    print("angle 3° metrics")
    print("PHC", map_.item())
    print("MAP", phc.item())
    print(f'Matches  :\n{matches}')

    map_, phc, _ = calculate_metrics_from_predictions(eval_predictions, get_match_sequence_plane_symmetry, {
        "eps": 0.01,
        "theta": 0.0038053019,
        "confidence_threshold": 0.1,
    })
    matches = get_match_sequence_plane_symmetry(item.points, plane_predictions[idx], item.plane_symmetries, {
        "eps": 0.01,
        "theta": 0.00137046524,
        "confidence_threshold": 0.0,
    })

    print("angle 5° metrics")
    print("PHC", map_.item())
    print("MAP", phc.item())
    print(f'Matches  :\n{matches}')


    map_, phc, _ = calculate_metrics_from_predictions(eval_predictions, get_match_sequence_plane_symmetry, {
        "eps": 1,
        "theta": 0.00015230484,
        "confidence_threshold": 0.1,
    })
    matches = get_match_sequence_plane_symmetry(item.points, plane_predictions[idx], item.plane_symmetries, {
        "eps": 1,
        "theta": 0.00015230484,
        "confidence_threshold": 0.0,
    })
    print("Normals matching")
    print("PHC", map_.item())
    print("MAP", phc.item())
    print(f'Matches  :\n{matches}')


    map_, phc, _ = calculate_metrics_from_predictions(eval_predictions, get_match_sequence_plane_symmetry, {
        "eps": 0.01,
        "theta": 6.28,
        "confidence_threshold": 0.0,
    })

    print("Center matching")
    print("PHC", map_.item())
    print("MAP", phc.item())
